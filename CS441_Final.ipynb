{"cells":[{"cell_type":"code","execution_count":10,"id":"d81f9240-fb40-408d-b2ac-f1701cc2aef8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"d81f9240-fb40-408d-b2ac-f1701cc2aef8","executionInfo":{"status":"ok","timestamp":1765477024230,"user_tz":360,"elapsed":6169,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"5621d762-8247-4bf6-ace5-3d3b42c5ea7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (2025.12.8)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (0.2.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n"]}],"source":["# install scraper to download audio from youtube\n","!pip install yt-dlp ffmpeg-python"]},{"cell_type":"code","source":["import os\n","import subprocess\n","from google.colab import drive\n","\n","# Only mount if the directory doesn't exist yet\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Drive is already mounted.\")\n","\n","# 2. Define the Root Directory for the project\n","# Final structure will be: .../cs441/final_project/blues/song.wav\n","PROJECT_ROOT = \"/content/drive/MyDrive/cs441/final_project\"\n","\n","# Helper function\n","def download_to_drive(url, category_name):\n","    # Construct the full path (e.g., .../final_project/blues)\n","    full_output_path = os.path.join(PROJECT_ROOT, category_name)\n","\n","    # Check if folder exists\n","    if not os.path.exists(full_output_path):\n","        os.makedirs(full_output_path)\n","        print(f\"Created new directory: {full_output_path}\")\n","    else:\n","        print(f\"Directory already exists: {full_output_path}\")\n","\n","    print(f\"Downloading {category_name} playlist...\")\n","\n","    # yt-dlp command\n","    cmd = [\n","        \"yt-dlp\",\n","        \"-x\", \"--audio-format\", \"wav\",\n","        \"--ignore-errors\",\n","        \"-o\", f\"{full_output_path}/%(title)s.%(ext)s\",\n","        url\n","    ]\n","    subprocess.run(cmd)\n","\n","# Data sources\n","\n","# 1. Blues Sources\n","blues_urls = [\n","    \"https://www.youtube.com/watch?v=JF1tzyxGHyw&list=PLYoJq2KGU2pX3WlASygnfORQampG4nNJx\", # delta blues\n","    \"https://www.youtube.com/watch?v=ioOzsi9aHQQ&list=PLFjmckBbDlzSE47xD0FivigDOARiLJl61\", # general blues\n","    \"https://www.youtube.com/watch?v=sD72LbIk02M&list=PLaSOVar1sXKzo5gsf-_jEPjhy8JQJ0F3e\" # modern blues\n","]\n","\n","# 2. Non-Blues Sources\n","not_blues_urls = [\n","    \"https://www.youtube.com/watch?v=ryA6eHZNnXY&list=PLV8JEVXS4su7_R87iyEjNZ-_qHtjbbUvB\", # jazz\n","    \"https://www.youtube.com/watch?v=AUO_5EALZoM&list=PL8EAA83325701CE9C\", # rock\n","    \"https://www.youtube.com/watch?v=P2l0lbn5TVg&list=PL2788304DC59DBEB4\", # classical\n","    \"https://www.youtube.com/watch?v=xFYQQPAOz7Y&list=PLOhV0FrFphUdkuWPE2bzJEsGxXMRKVkoM\" # hip-hop\n","]\n","\n","# # Download data\n","\n","print(\"--- Processing Blues Data ---\")\n","for link in blues_urls:\n","    # This puts files in: .../final_project/blues/\n","    download_to_drive(link, \"blues\")\n","\n","print(\"\\n--- Processing Non-Blues Data ---\")\n","for link in not_blues_urls:\n","    # This puts files in: .../final_project/not_blues/\n","    download_to_drive(link, \"not_blues\")\n","\n","print(\"\\nAll downloads finished! Check your Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"aj-WpO0kewfv","executionInfo":{"status":"ok","timestamp":1765479971206,"user_tz":360,"elapsed":762981,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"c3a689f5-2b6f-4fd6-dccf-218849d254a0"},"id":"aj-WpO0kewfv","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive is already mounted.\n","\n","--- Processing Non-Blues Data ---\n","Directory already exists: /content/drive/MyDrive/cs441/final_project/not_blues\n","Downloading not_blues playlist...\n","Directory already exists: /content/drive/MyDrive/cs441/final_project/not_blues\n","Downloading not_blues playlist...\n","Directory already exists: /content/drive/MyDrive/cs441/final_project/not_blues\n","Downloading not_blues playlist...\n","Directory already exists: /content/drive/MyDrive/cs441/final_project/not_blues\n","Downloading not_blues playlist...\n","\n","All downloads finished! Check your Drive.\n"]}]},{"cell_type":"code","source":["!pip install librosa soundfile numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bsby083fqBMl","executionInfo":{"status":"ok","timestamp":1765480087612,"user_tz":360,"elapsed":5464,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"45209a12-5828-4eb3-db62-24ab5e6b24f1"},"id":"bsby083fqBMl","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n","Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import librosa\n","import soundfile as sf\n","import os\n","import numpy as np\n","from google.colab import drive\n","\n","# Root to data\n","PROJECT_ROOT = \"/content/drive/MyDrive/cs441/final_project\"\n","\n","# Define folder for chopped-up data\n","OUTPUT_ROOT = os.path.join(PROJECT_ROOT, \"processed_data\")\n","\n","def process_audio_folder(input_folder, output_folder, label, chunk_duration=30):\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    valid_exts = ('.wav', '.mp3', '.m4a', '.webm', '.flac')\n","    files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_exts)]\n","\n","    print(f\"Found {len(files)} audio files in {input_folder}\")\n","    print(f\"Processing {label}...\")\n","\n","    clip_id = 0\n","\n","    for file in files:\n","        file_path = os.path.join(input_folder, file)\n","\n","        try:\n","            # 1. Load the audio\n","            # Librosa automatically converts mp3/webm/etc to raw audio here\n","            audio, sr = librosa.load(file_path, sr=22050, mono=True)\n","\n","            # 2. Calculate samples per chunk\n","            samples_per_chunk = chunk_duration * sr\n","            total_samples = len(audio)\n","\n","            # 3. Slice the audio\n","            for start_idx in range(0, total_samples, samples_per_chunk):\n","                end_idx = start_idx + samples_per_chunk\n","\n","                # Check if we have a full 30-second chunk\n","                if end_idx < total_samples:\n","                    chunk = audio[start_idx:end_idx]\n","\n","                    # 4. Save the chunk\n","                    output_filename = f\"{label}.{str(clip_id).zfill(5)}.wav\"\n","                    output_path = os.path.join(output_folder, output_filename)\n","\n","                    sf.write(output_path, chunk, sr)\n","                    clip_id += 1\n","\n","            Print progress every 10 files\n","            if clip_id % 10 == 0:\n","                print(f\"  Created {clip_id} clips so far...\")\n","\n","        except Exception as e:\n","            print(f\"Error processing {file}: {e}\")\n","\n","# Tell google where the inputs and outputs are\n","\n","# Define the full inputs\n","input_blues = os.path.join(PROJECT_ROOT, \"blues\")\n","input_not_blues = os.path.join(PROJECT_ROOT, \"not_blues\")\n","\n","# Define the full outputs\n","output_blues = os.path.join(OUTPUT_ROOT, \"blues\")\n","output_not_blues = os.path.join(OUTPUT_ROOT, \"not_blues\")\n","\n","# Process the audio\n","print(\"--- Starting Processing Pipeline ---\")\n","process_audio_folder(input_blues, output_blues, \"blues\")\n","process_audio_folder(input_not_blues, output_not_blues, \"not_blues\")\n","\n","print(\"\\nPipeline Complete.\")\n","print(f\"Processed data saved to: {OUTPUT_ROOT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"6r-eF5NZ0Cpt","executionInfo":{"status":"ok","timestamp":1765480686908,"user_tz":360,"elapsed":460526,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"45c92172-5170-464b-aa7a-3a6e357b6f32"},"id":"6r-eF5NZ0Cpt","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Processing Pipeline ---\n","Found 180 audio files in /content/drive/MyDrive/cs441/final_project/blues\n","Processing blues...\n","  Created 130 clips so far...\n","  Created 340 clips so far...\n","  Created 450 clips so far...\n","  Created 470 clips so far...\n","  Created 510 clips so far...\n","  Created 560 clips so far...\n","  Created 590 clips so far...\n","  Created 600 clips so far...\n","  Created 630 clips so far...\n","  Created 840 clips so far...\n","  Created 910 clips so far...\n","  Created 920 clips so far...\n","  Created 950 clips so far...\n","  Created 1210 clips so far...\n","  Created 1740 clips so far...\n","  Created 2140 clips so far...\n","Found 213 audio files in /content/drive/MyDrive/cs441/final_project/not_blues\n","Processing not_blues...\n","  Created 100 clips so far...\n","  Created 160 clips so far...\n","  Created 210 clips so far...\n","  Created 270 clips so far...\n","  Created 280 clips so far...\n","  Created 350 clips so far...\n","  Created 360 clips so far...\n","  Created 390 clips so far...\n","  Created 410 clips so far...\n","  Created 450 clips so far...\n","  Created 610 clips so far...\n","  Created 650 clips so far...\n","  Created 730 clips so far...\n","  Created 740 clips so far...\n","  Created 920 clips so far...\n","  Created 1040 clips so far...\n","  Created 1200 clips so far...\n","  Created 1280 clips so far...\n","  Created 1370 clips so far...\n","  Created 1650 clips so far...\n","  Created 1670 clips so far...\n","  Created 1710 clips so far...\n","  Created 1720 clips so far...\n","  Created 1890 clips so far...\n","\n","‚úÖ Pipeline Complete.\n","Processed data saved to: /content/drive/MyDrive/cs441/final_project/processed_data\n"]}]},{"cell_type":"code","source":["import librosa\n","import soundfile as sf\n","import os\n","import re # We need regex to clean messy filenames\n","\n","# 1. SETUP PATHS\n","PROJECT_ROOT = \"/content/drive/MyDrive/cs441/final_project\"\n","OUTPUT_ROOT = os.path.join(PROJECT_ROOT, \"processed_data_named\") # New folder\n","\n","def clean_filename(fname):\n","    # Removes spaces and weird characters so code doesn't break\n","    # \"B.B. King - Thrill.wav\" -> \"BB_King_-_Thrill\"\n","    name = os.path.splitext(fname)[0]\n","    return re.sub(r'[^a-zA-Z0-9]', '_', name)\n","\n","def process_audio_folder(input_folder, output_folder, label, chunk_duration=30):\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    valid_exts = ('.wav', '.mp3', '.m4a', '.webm', '.flac')\n","    files = [f for f in os.listdir(input_folder) if f.lower().endswith(valid_exts)]\n","\n","    print(f\"Processing {label}...\")\n","\n","    for file in files:\n","        file_path = os.path.join(input_folder, file)\n","        safe_name = clean_filename(file)\n","\n","        try:\n","            audio, sr = librosa.load(file_path, sr=22050, mono=True)\n","            samples_per_chunk = chunk_duration * sr\n","            total_samples = len(audio)\n","\n","            chunk_count = 0\n","\n","            for start_idx in range(0, total_samples, samples_per_chunk):\n","                end_idx = start_idx + samples_per_chunk\n","\n","                if end_idx < total_samples:\n","                    chunk = audio[start_idx:end_idx]\n","\n","                    # Include the cleaned up filename\n","                    output_filename = f\"{label}.{safe_name}.{str(chunk_count).zfill(3)}.wav\"\n","                    output_path = os.path.join(output_folder, output_filename)\n","\n","                    sf.write(output_path, chunk, sr)\n","                    chunk_count += 1\n","\n","        except Exception as e:\n","            print(f\"Error processing {file}: {e}\")\n","\n","# Execute processing\n","input_blues = os.path.join(PROJECT_ROOT, \"blues\")\n","input_not_blues = os.path.join(PROJECT_ROOT, \"not_blues\")\n","\n","output_blues = os.path.join(OUTPUT_ROOT, \"blues\")\n","output_not_blues = os.path.join(OUTPUT_ROOT, \"not_blues\")\n","\n","process_audio_folder(input_blues, output_blues, \"blues\")\n","process_audio_folder(input_not_blues, output_not_blues, \"not_blues\")\n","\n","print(\"Done! Files now have real names.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"pQ_R9cbe82Ir","executionInfo":{"status":"ok","timestamp":1765482872877,"user_tz":360,"elapsed":456495,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"15a142e0-f588-4fd6-c022-af2d4d1b1310"},"id":"pQ_R9cbe82Ir","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing blues...\n","Processing not_blues...\n","Done! Files now have real names.\n"]}]},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import os\n","import csv\n","from google.colab import drive\n","\n","# 1. SETUP PATHS\n","# Input: Where your chopped-up wav files are\n","INPUT_ROOT = \"/content/drive/MyDrive/cs441/final_project/processed_data\"\n","# Output: Where to save the spreadsheet\n","OUTPUT_FILE = \"/content/drive/MyDrive/cs441/final_project/blues_features.csv\"\n","\n","# 2. SETUP THE CSV FILE\n","# We will have 20 columns for MFCCs (mfcc1...mfcc20) and 1 column for the Label\n","header = 'filename'\n","for i in range(1, 21):\n","    header += f' mfcc{i}'\n","header += ' label'\n","header = header.split()\n","\n","# Create the file and write the header row\n","file = open(OUTPUT_FILE, 'w', newline='')\n","with file:\n","    writer = csv.writer(file)\n","    writer.writerow(header)\n","\n","# 3. DEFINE EXTRACTION LOOP\n","genres = ['blues', 'not_blues']\n","\n","print(f\"--- Starting Feature Extraction ---\")\n","print(f\"Reading from: {INPUT_ROOT}\")\n","print(f\"Saving to:    {OUTPUT_FILE}\")\n","\n","count = 0\n","\n","for g in genres:\n","    folder_path = os.path.join(INPUT_ROOT, g)\n","\n","    # Check if folder exists\n","    if not os.path.exists(folder_path):\n","        print(f\"Warning: Folder not found: {folder_path}\")\n","        continue\n","\n","    files = os.listdir(folder_path)\n","    print(f\"\\nProcessing {g} ({len(files)} files)...\")\n","\n","    for filename in files:\n","        songpath = os.path.join(folder_path, filename)\n","\n","        try:\n","            # A. Load the audio file\n","            y, sr = librosa.load(songpath, mono=True, duration=30)\n","\n","            # B. Extract MFCCs\n","            # This returns a matrix (20 rows x time)\n","            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n","\n","            # C. Squash it down\n","            # We take the MEAN (average) across time to get 20 single numbers\n","            mfcc_mean = np.mean(mfcc.T, axis=0)\n","\n","            # D. Prepare the row for the CSV\n","            to_append = f'{filename}'\n","            for e in mfcc_mean:\n","                to_append += f' {e}'\n","            to_append += f' {g}'\n","\n","            # E. Write to CSV\n","            file = open(OUTPUT_FILE, 'a', newline='')\n","            with file:\n","                writer = csv.writer(file)\n","                writer.writerow(to_append.split())\n","\n","            count += 1\n","            if count % 50 == 0:\n","                print(f\"  Extracted features for {count} songs...\")\n","\n","        except Exception as e:\n","            print(f\"Error with {filename}: {e}\")\n","\n","print(f\"\\nExtraction Complete! Saved to {OUTPUT_FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"1LQHiLm80l3s","executionInfo":{"status":"ok","timestamp":1765481191984,"user_tz":360,"elapsed":297418,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"4f1db289-2dd7-4728-9855-c7e66af7ea41"},"id":"1LQHiLm80l3s","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Feature Extraction ---\n","Reading from: /content/drive/MyDrive/cs441/final_project/processed_data\n","Saving to:    /content/drive/MyDrive/cs441/final_project/blues_features.csv\n","\n","Processing blues (2207 files)...\n","  Extracted features for 50 songs...\n","  Extracted features for 100 songs...\n","  Extracted features for 150 songs...\n","  Extracted features for 200 songs...\n","  Extracted features for 250 songs...\n","  Extracted features for 300 songs...\n","  Extracted features for 350 songs...\n","  Extracted features for 400 songs...\n","  Extracted features for 450 songs...\n","  Extracted features for 500 songs...\n","  Extracted features for 550 songs...\n","  Extracted features for 600 songs...\n","  Extracted features for 650 songs...\n","  Extracted features for 700 songs...\n","  Extracted features for 750 songs...\n","  Extracted features for 800 songs...\n","  Extracted features for 850 songs...\n","  Extracted features for 900 songs...\n","  Extracted features for 950 songs...\n","  Extracted features for 1000 songs...\n","  Extracted features for 1050 songs...\n","  Extracted features for 1100 songs...\n","  Extracted features for 1150 songs...\n","  Extracted features for 1200 songs...\n","  Extracted features for 1250 songs...\n","  Extracted features for 1300 songs...\n","  Extracted features for 1350 songs...\n","  Extracted features for 1400 songs...\n","  Extracted features for 1450 songs...\n","  Extracted features for 1500 songs...\n","  Extracted features for 1550 songs...\n","  Extracted features for 1600 songs...\n","  Extracted features for 1650 songs...\n","  Extracted features for 1700 songs...\n","  Extracted features for 1750 songs...\n","  Extracted features for 1800 songs...\n","  Extracted features for 1850 songs...\n","  Extracted features for 1900 songs...\n","  Extracted features for 1950 songs...\n","  Extracted features for 2000 songs...\n","  Extracted features for 2050 songs...\n","  Extracted features for 2100 songs...\n","  Extracted features for 2150 songs...\n","  Extracted features for 2200 songs...\n","\n","Processing not_blues (1890 files)...\n","  Extracted features for 2250 songs...\n","  Extracted features for 2300 songs...\n","  Extracted features for 2350 songs...\n","  Extracted features for 2400 songs...\n","  Extracted features for 2450 songs...\n","  Extracted features for 2500 songs...\n","  Extracted features for 2550 songs...\n","  Extracted features for 2600 songs...\n","  Extracted features for 2650 songs...\n","  Extracted features for 2700 songs...\n","  Extracted features for 2750 songs...\n","  Extracted features for 2800 songs...\n","  Extracted features for 2850 songs...\n","  Extracted features for 2900 songs...\n","  Extracted features for 2950 songs...\n","  Extracted features for 3000 songs...\n","  Extracted features for 3050 songs...\n","  Extracted features for 3100 songs...\n","  Extracted features for 3150 songs...\n","  Extracted features for 3200 songs...\n","  Extracted features for 3250 songs...\n","  Extracted features for 3300 songs...\n","  Extracted features for 3350 songs...\n","  Extracted features for 3400 songs...\n","  Extracted features for 3450 songs...\n","  Extracted features for 3500 songs...\n","  Extracted features for 3550 songs...\n","  Extracted features for 3600 songs...\n","  Extracted features for 3650 songs...\n","  Extracted features for 3700 songs...\n","  Extracted features for 3750 songs...\n","  Extracted features for 3800 songs...\n","  Extracted features for 3850 songs...\n","  Extracted features for 3900 songs...\n","  Extracted features for 3950 songs...\n","  Extracted features for 4000 songs...\n","  Extracted features for 4050 songs...\n","\n","‚úÖ Extraction Complete! Saved to /content/drive/MyDrive/cs441/final_project/blues_features.csv\n"]}]},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import os\n","import csv\n","from google.colab import drive\n","\n","# 1. SETUP PATHS\n","# Input: Where your chopped-up wav files are\n","INPUT_ROOT = \"/content/drive/MyDrive/cs441/final_project/processed_data_named\"\n","# Output: Where to save the spreadsheet\n","OUTPUT_FILE = \"/content/drive/MyDrive/cs441/final_project/blues_features_named.csv\"\n","\n","# 2. SETUP THE CSV FILE\n","# We will have 20 columns for MFCCs (mfcc1...mfcc20) and 1 column for the Label\n","header = 'filename'\n","for i in range(1, 21):\n","    header += f' mfcc{i}'\n","header += ' label'\n","header = header.split()\n","\n","# Create the file and write the header row\n","file = open(OUTPUT_FILE, 'w', newline='')\n","with file:\n","    writer = csv.writer(file)\n","    writer.writerow(header)\n","\n","# 3. DEFINE EXTRACTION LOOP\n","genres = ['blues', 'not_blues']\n","\n","print(f\"--- Starting Feature Extraction ---\")\n","print(f\"Reading from: {INPUT_ROOT}\")\n","print(f\"Saving to:    {OUTPUT_FILE}\")\n","\n","count = 0\n","\n","for g in genres:\n","    folder_path = os.path.join(INPUT_ROOT, g)\n","\n","    # Check if folder exists\n","    if not os.path.exists(folder_path):\n","        print(f\"Warning: Folder not found: {folder_path}\")\n","        continue\n","\n","    files = os.listdir(folder_path)\n","    print(f\"\\nProcessing {g} ({len(files)} files)...\")\n","\n","    for filename in files:\n","        songpath = os.path.join(folder_path, filename)\n","\n","        try:\n","            # A. Load the audio file\n","            y, sr = librosa.load(songpath, mono=True, duration=30)\n","\n","            # B. Extract MFCCs\n","            # This returns a matrix (20 rows x time)\n","            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n","\n","            # C. Squash it down\n","            # We take the MEAN (average) across time to get 20 single numbers\n","            mfcc_mean = np.mean(mfcc.T, axis=0)\n","\n","            # D. Prepare the row for the CSV\n","            to_append = f'{filename}'\n","            for e in mfcc_mean:\n","                to_append += f' {e}'\n","            to_append += f' {g}'\n","\n","            # E. Write to CSV\n","            file = open(OUTPUT_FILE, 'a', newline='')\n","            with file:\n","                writer = csv.writer(file)\n","                writer.writerow(to_append.split())\n","\n","            count += 1\n","            if count % 50 == 0:\n","                print(f\"  Extracted features for {count} songs...\")\n","\n","        except Exception as e:\n","            print(f\"Error with {filename}: {e}\")\n","\n","print(f\"\\nExtraction Complete! Saved to {OUTPUT_FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ulfpSyAu-8jh","executionInfo":{"status":"ok","timestamp":1765483258495,"user_tz":360,"elapsed":294338,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"8ef33e86-79e4-4a79-8d78-b6816510c2cf"},"id":"ulfpSyAu-8jh","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Feature Extraction ---\n","Reading from: /content/drive/MyDrive/cs441/final_project/processed_data_named\n","Saving to:    /content/drive/MyDrive/cs441/final_project/blues_features_named.csv\n","\n","Processing blues (2207 files)...\n","  Extracted features for 50 songs...\n","  Extracted features for 100 songs...\n","  Extracted features for 150 songs...\n","  Extracted features for 200 songs...\n","  Extracted features for 250 songs...\n","  Extracted features for 300 songs...\n","  Extracted features for 350 songs...\n","  Extracted features for 400 songs...\n","  Extracted features for 450 songs...\n","  Extracted features for 500 songs...\n","  Extracted features for 550 songs...\n","  Extracted features for 600 songs...\n","  Extracted features for 650 songs...\n","  Extracted features for 700 songs...\n","  Extracted features for 750 songs...\n","  Extracted features for 800 songs...\n","  Extracted features for 850 songs...\n","  Extracted features for 900 songs...\n","  Extracted features for 950 songs...\n","  Extracted features for 1000 songs...\n","  Extracted features for 1050 songs...\n","  Extracted features for 1100 songs...\n","  Extracted features for 1150 songs...\n","  Extracted features for 1200 songs...\n","  Extracted features for 1250 songs...\n","  Extracted features for 1300 songs...\n","  Extracted features for 1350 songs...\n","  Extracted features for 1400 songs...\n","  Extracted features for 1450 songs...\n","  Extracted features for 1500 songs...\n","  Extracted features for 1550 songs...\n","  Extracted features for 1600 songs...\n","  Extracted features for 1650 songs...\n","  Extracted features for 1700 songs...\n","  Extracted features for 1750 songs...\n","  Extracted features for 1800 songs...\n","  Extracted features for 1850 songs...\n","  Extracted features for 1900 songs...\n","  Extracted features for 1950 songs...\n","  Extracted features for 2000 songs...\n","  Extracted features for 2050 songs...\n","  Extracted features for 2100 songs...\n","  Extracted features for 2150 songs...\n","  Extracted features for 2200 songs...\n","\n","Processing not_blues (1890 files)...\n","  Extracted features for 2250 songs...\n","  Extracted features for 2300 songs...\n","  Extracted features for 2350 songs...\n","  Extracted features for 2400 songs...\n","  Extracted features for 2450 songs...\n","  Extracted features for 2500 songs...\n","  Extracted features for 2550 songs...\n","  Extracted features for 2600 songs...\n","  Extracted features for 2650 songs...\n","  Extracted features for 2700 songs...\n","  Extracted features for 2750 songs...\n","  Extracted features for 2800 songs...\n","  Extracted features for 2850 songs...\n","  Extracted features for 2900 songs...\n","  Extracted features for 2950 songs...\n","  Extracted features for 3000 songs...\n","  Extracted features for 3050 songs...\n","  Extracted features for 3100 songs...\n","  Extracted features for 3150 songs...\n","  Extracted features for 3200 songs...\n","  Extracted features for 3250 songs...\n","  Extracted features for 3300 songs...\n","  Extracted features for 3350 songs...\n","  Extracted features for 3400 songs...\n","  Extracted features for 3450 songs...\n","  Extracted features for 3500 songs...\n","  Extracted features for 3550 songs...\n","  Extracted features for 3600 songs...\n","  Extracted features for 3650 songs...\n","  Extracted features for 3700 songs...\n","  Extracted features for 3750 songs...\n","  Extracted features for 3800 songs...\n","  Extracted features for 3850 songs...\n","  Extracted features for 3900 songs...\n","  Extracted features for 3950 songs...\n","  Extracted features for 4000 songs...\n","  Extracted features for 4050 songs...\n","\n","Extraction Complete! Saved to /content/drive/MyDrive/cs441/final_project/blues_features_named.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","# Import the 6 models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n","# 1. LOAD DATA\n","# Ensure this matches actual path\n","data_path = \"/content/drive/MyDrive/cs441/final_project/blues_features.csv\"\n","data = pd.read_csv(data_path)\n","\n","# 2. PREPARE DATA\n","# Drop filename, separate features (X) and label (y)\n","X = data.drop(['filename', 'label'], axis=1)\n","y = data['label']\n","\n","# Encode labels (Blues=1, Not_Blues=0)\n","encoder = LabelEncoder()\n","y = encoder.fit_transform(y)\n","\n","# 3. SPLIT DATA\n","# 80% Training, 20% Testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 4. SCALE DATA\n","# Crucial for SVM and Logistic Regression to work correctly\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# 5. DEFINE MODELS\n","models = {\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"Naive Bayes\":         GaussianNB(),\n","    \"SVM\":                 SVC(),\n","    \"Decision Tree\":       DecisionTreeClassifier(),\n","    \"Random Forest\":       RandomForestClassifier(n_estimators=100),\n","    \"Boosted Tree\":        GradientBoostingClassifier(n_estimators=100)\n","}"],"metadata":{"id":"YX80qfu33JAT","executionInfo":{"status":"ok","timestamp":1765481748619,"user_tz":360,"elapsed":2935,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}}},"id":"YX80qfu33JAT","execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 6. TRAIN AND EVALUATE\n","print(f\"{'Model Name':<25} | {'RMSE':<10} | {'Accuracy':<10}\")\n","print(\"-\" * 50)\n","\n","results = {}\n","\n","for name, model in models.items():\n","    # Train the model\n","    model.fit(X_train_scaled, y_train)\n","\n","    # Predict (Get 0s and 1s)\n","    predictions = model.predict(X_test_scaled)\n","\n","    # Calculate RMSE\n","    # Set squared=False to get RMSE (Root Mean Squared Error)\n","    mse = mean_squared_error(y_test, predictions)\n","    rmse = np.sqrt(mse)\n","\n","    # Calculate Accuracy for context\n","    acc = accuracy_score(y_test, predictions)\n","\n","    results[name] = rmse\n","\n","    # Print row\n","    print(f\"{name:<25} | {rmse:.4f}     | {acc*100:.1f}%\")\n","\n","# 7. FIND THE WINNER\n","best_model = min(results, key=results.get)\n","print(\"-\" * 50)\n","print(f\"Best Model (Lowest RMSE): {best_model}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ugdGNrT-6YzC","executionInfo":{"status":"ok","timestamp":1765481829190,"user_tz":360,"elapsed":6771,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"5d20a2c2-a996-4e6d-9058-7080006339ae"},"id":"ugdGNrT-6YzC","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Name                | RMSE       | Accuracy  \n","--------------------------------------------------\n","Logistic Regression       | 0.4826     | 76.7%\n","Naive Bayes               | 0.5144     | 73.5%\n","SVM                       | 0.3104     | 90.4%\n","Decision Tree             | 0.4417     | 80.5%\n","Random Forest             | 0.3162     | 90.0%\n","Boosted Tree              | 0.3997     | 84.0%\n","--------------------------------------------------\n","Best Model (Lowest RMSE): SVM\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# 1. LOAD DATA\n","data_path = \"/content/drive/MyDrive/cs441/final_project/blues_features.csv\"\n","df = pd.read_csv(data_path)\n","\n","# 2. PREPARE DATA\n","X = df.drop(['filename', 'label'], axis=1)\n","filenames = df['filename']\n","\n","# Blues = 1, Not_Blues = 0\n","y = df['label'].map({'blues': 1, 'not_blues': 0})\n","\n","# 3. SPLIT EVERYTHING\n","X_train, X_test, y_train, y_test, files_train, files_test = train_test_split(\n","    X, y, filenames, test_size=0.2, random_state=42\n",")\n","\n","# 4. TRAIN MODEL\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 5. GET PROBABILITIES\n","# Column 1 is the probability of Class 1 (forced to be Blues)\n","probs = model.predict_proba(X_test)[:, 1]\n","\n","# 6. CREATE RESULTS TABLE\n","results = pd.DataFrame({\n","    'filename': files_test,\n","    'actual_label': y_test, # 1 is Blues, 0 is Not Blues\n","    'blues_probability': probs\n","})\n","\n","# --- FIND THE EXTREMES ---\n","print(\"--- CORRECTED MODEL ANALYSIS ---\\n\")\n","\n","# A. MOST BLUESY BLUES (True Blues, Highest Score)\n","# We want Label 1 (Blues) and Highest Probability\n","most_bluesy = results[results['actual_label'] == 1].sort_values(by='blues_probability', ascending=False).head(1)\n","print(f\"The 'Most Bluesy' Blues Song (Model Confidence: {most_bluesy.iloc[0]['blues_probability']*100:.1f}%)\")\n","print(f\"   File: {most_bluesy.iloc[0]['filename']}\")\n","\n","# B. LEAST BLUESY BLUES (True Blues, Lowest Score)\n","# We want Label 1 (Blues) but Lowest Probability (Model thought it was pop/rock)\n","least_bluesy = results[results['actual_label'] == 1].sort_values(by='blues_probability', ascending=True).head(1)\n","print(f\"\\nThe 'Least Bluesy' Blues Song (Model Confidence: {least_bluesy.iloc[0]['blues_probability']*100:.1f}%)\")\n","print(f\"   File: {least_bluesy.iloc[0]['filename']}\")\n","print(\"   (This is a Blues song, but the model missed it!)\")\n","\n","# C. MOST BLUESY NON-BLUES (The Impostor)\n","# We want Label 0 (Not Blues) but Highest Probability\n","impostor = results[results['actual_label'] == 0].sort_values(by='blues_probability', ascending=False).head(1)\n","print(f\"\\nThe 'Most Bluesy' NON-Blues Song (Model thought it was Blues: {impostor.iloc[0]['blues_probability']*100:.1f}%)\")\n","print(f\"   File: {impostor.iloc[0]['filename']}\")\n","\n","# D. LEAST BLUESY NON-BLUES (The Obvious Non-Blues)\n","# We want Label 0 (Not Blues) and Lowest Probability\n","least_bluesy_non = results[results['actual_label'] == 0].sort_values(by='blues_probability', ascending=True).head(1)\n","print(f\"\\nThe 'Least Bluesy' NON-Blues Song (Model Confidence: {least_bluesy_non.iloc[0]['blues_probability']*100:.1f}%)\")\n","print(f\"   File: {least_bluesy_non.iloc[0]['filename']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"wV67bS9x6dEb","executionInfo":{"status":"ok","timestamp":1765482138761,"user_tz":360,"elapsed":2242,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"938066ac-29b9-40b9-9096-1be394b44038"},"id":"wV67bS9x6dEb","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["--- üîç CORRECTED MODEL ANALYSIS ---\n","\n","The 'Most Bluesy' Blues Song (Model Confidence: 100.0%)\n","   File: blues.01722.wav\n","\n","The 'Least Bluesy' Blues Song (Model Confidence: 18.0%)\n","   File: blues.01838.wav\n","   (This is a Blues song, but the model missed it!)\n","\n","The 'Most Bluesy' NON-Blues Song (Model thought it was Blues: 81.0%)\n","   File: not_blues.00419.wav\n","\n","The 'Least Bluesy' NON-Blues Song (Model Confidence: 0.0%)\n","   File: not_blues.00589.wav\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","# Import models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n","# ==========================================\n","# 1. LOAD AND PREPARE DATA\n","# ==========================================\n","data_path = \"/content/drive/MyDrive/cs441/final_project/blues_features_named.csv\"\n","df = pd.read_csv(data_path)\n","\n","# Separate parts\n","X = df.drop(['filename', 'label'], axis=1)\n","filenames = df['filename'] # We keep this safe for later!\n","\n","# --- CONSISTENT MAPPING ---\n","# We force Blues=1 and Not_Blues=0 for ALL models\n","y = df['label'].map({'blues': 1, 'not_blues': 0})\n","\n","# Split Data (keeping filenames aligned)\n","# 80% Training, 20% Testing\n","X_train, X_test, y_train, y_test, files_train, files_test = train_test_split(\n","    X, y, filenames, test_size=0.2, random_state=42\n",")\n","\n","# Scale Data (Crucial for SVM/Logistic)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# ==========================================\n","# 2. TRAIN ALL 6 MODELS\n","# ==========================================\n","models = {\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"Naive Bayes\":         GaussianNB(),\n","    # Probability=True needed for SVM to give confidence scores later\n","    \"SVM\":                 SVC(probability=True),\n","    \"Decision Tree\":       DecisionTreeClassifier(),\n","    \"Random Forest\":       RandomForestClassifier(n_estimators=100, random_state=42),\n","    \"Boosted Tree\":        GradientBoostingClassifier(n_estimators=100, random_state=42)\n","}\n","\n","print(f\"{'Model Name':<25} | {'RMSE':<10} | {'Accuracy':<10}\")\n","print(\"-\" * 50)\n","\n","results_rmse = {}\n","trained_models = {}\n","\n","for name, model in models.items():\n","    # Train\n","    model.fit(X_train_scaled, y_train)\n","    trained_models[name] = model\n","\n","    # Predict\n","    predictions = model.predict(X_test_scaled)\n","\n","    # Metrics\n","    mse = mean_squared_error(y_test, predictions)\n","    rmse = np.sqrt(mse)\n","    acc = accuracy_score(y_test, predictions)\n","\n","    results_rmse[name] = rmse\n","\n","    print(f\"{name:<25} | {rmse:.4f}     | {acc*100:.1f}%\")\n","\n","# ==========================================\n","# 3. SELECT THE WINNER\n","# ==========================================\n","best_model_name = min(results_rmse, key=results_rmse.get)\n","best_model = trained_models[best_model_name]\n","\n","print(\"-\" * 50)\n","print(f\"Best Model: {best_model_name} (RMSE: {results_rmse[best_model_name]:.4f})\")\n","print(\"-\" * 50)\n","\n","# ==========================================\n","# 4. DETAILED ANALYSIS (USING NAMED FILES)\n","# ==========================================\n","# We use the Best Model to find the \"Most Bluesy\" songs\n","\n","# Get probabilities for the Test Set\n","# Column 1 = Probability of being Blues (since we mapped Blues=1)\n","try:\n","    probs = best_model.predict_proba(X_test_scaled)[:, 1]\n","\n","    # Create a DataFrame for analysis\n","    analysis = pd.DataFrame({\n","        'filename': files_test,      # <--- THIS NOW HAS THE REAL NAMES\n","        'actual_label': y_test,      # 1=Blues, 0=Not_Blues\n","        'blues_prob': probs\n","    })\n","\n","    print(f\"\\nANALYSIS USING {best_model_name.upper()}\\n\")\n","\n","    # A. MOST BLUESY BLUES\n","    # Filter: Actual=1, Sort: Prob Descending\n","    top_blues = analysis[analysis['actual_label'] == 1].sort_values(by='blues_prob', ascending=False).head(1)\n","    if not top_blues.empty:\n","        print(f\"The 'Most Bluesy' Blues Song (Confidence: {top_blues.iloc[0]['blues_prob']*100:.1f}%)\")\n","        print(f\"   File: {top_blues.iloc[0]['filename']}\")\n","\n","    # B. LEAST BLUESY BLUES (Outlier)\n","    # Filter: Actual=1, Sort: Prob Ascending\n","    bad_blues = analysis[analysis['actual_label'] == 1].sort_values(by='blues_prob', ascending=True).head(1)\n","    if not bad_blues.empty:\n","        print(f\"\\nThe 'Least Bluesy' Blues Song (Confidence: {bad_blues.iloc[0]['blues_prob']*100:.1f}%)\")\n","        print(f\"   File: {bad_blues.iloc[0]['filename']}\")\n","        print(\"   (Model didn't think this sounded like Blues)\")\n","\n","    # C. MOST BLUESY NON-BLUES (Impostor)\n","    # Filter: Actual=0, Sort: Prob Descending\n","    impostor = analysis[analysis['actual_label'] == 0].sort_values(by='blues_prob', ascending=False).head(1)\n","    if not impostor.empty:\n","        print(f\"\\nüïµÔ∏è The 'Most Bluesy' NON-Blues Song (Model Confused: {impostor.iloc[0]['blues_prob']*100:.1f}%)\")\n","        print(f\"   File: {impostor.iloc[0]['filename']}\")\n","\n","    # D. LEAST BLUESY NON-BLUES (Obvious Non-Blues)\n","    # Filter: Actual=0, Sort: Prob Ascending\n","    clear_not = analysis[analysis['actual_label'] == 0].sort_values(by='blues_prob', ascending=True).head(1)\n","    if not clear_not.empty:\n","        print(f\"\\nThe 'Least Bluesy' NON-Blues Song (Confidence: {clear_not.iloc[0]['blues_prob']*100:.1f}%)\")\n","        print(f\"   File: {clear_not.iloc[0]['filename']}\")\n","\n","except AttributeError:\n","    print(f\"\\nThe winning model ({best_model_name}) does not support probability scores.\")\n","    print(\"Switching to Random Forest for detailed analysis...\")\n","    # Fallback to Random Forest if the winner (e.g., some SVMs) doesn't do probabilities well\n","    rf = trained_models[\"Random Forest\"]\n","    probs = rf.predict_proba(X_test_scaled)[:, 1]\n","    # (Re-run the analysis logic above if needed, but RF usually wins anyway)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"2V9QFhoX7ZgD","executionInfo":{"status":"ok","timestamp":1765483321780,"user_tz":360,"elapsed":8265,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"27a3f8b2-d3e5-4ceb-f73f-3bfca49f462d"},"id":"2V9QFhoX7ZgD","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Name                | RMSE       | Accuracy  \n","--------------------------------------------------\n","Logistic Regression       | 0.4826     | 76.7%\n","Naive Bayes               | 0.5250     | 72.4%\n","SVM                       | 0.3313     | 89.0%\n","Decision Tree             | 0.4593     | 78.9%\n","Random Forest             | 0.3238     | 89.5%\n","Boosted Tree              | 0.4334     | 81.2%\n","--------------------------------------------------\n","Best Model: Random Forest (RMSE: 0.3238)\n","--------------------------------------------------\n","\n","ANALYSIS USING RANDOM FOREST\n","\n","The 'Most Bluesy' Blues Song (Confidence: 100.0%)\n","   File: blues.Whiskey_Blues___B_B__King_Style_Blues_For_Escape___1_Hour_Deep_Soul.106.wav\n","\n","The 'Least Bluesy' Blues Song (Confidence: 7.0%)\n","   File: blues.Alabama_Shakes___Always_Alright__Live_on_SNL_.007.wav\n","   (Model didn't think this sounded like Blues)\n","\n","üïµÔ∏è The 'Most Bluesy' NON-Blues Song (Model Confused: 78.0%)\n","   File: not_blues.The_Notorious_B_I_G____Sky_s_The_Limit__Official_Music_Video___4K_.001.wav\n","\n","The 'Least Bluesy' NON-Blues Song (Confidence: 0.0%)\n","   File: not_blues.Rick_Ross___Hold_Me_Back__Explicit_.001.wav\n"]}]},{"cell_type":"code","source":["import os\n","from IPython.display import Audio, display\n","\n","# 1. SETUP PATHS\n","# Make sure this matches where your named files are\n","BASE_PATH = \"/content/drive/MyDrive/cs441/final_project/processed_data_named\"\n","\n","def play_specific_song(filename):\n","    # Determine which folder it's in based on the filename prefix\n","    if filename.startswith(\"blues\"):\n","        folder = \"blues\"\n","    else:\n","        folder = \"not_blues\"\n","\n","    full_path = os.path.join(BASE_PATH, folder, filename)\n","\n","    if os.path.exists(full_path):\n","        print(f\"Playing: {filename}\")\n","        # Create the audio player widget\n","        display(Audio(full_path))\n","    else:\n","        print(f\"Could not find file: {full_path}\")\n","\n","# ==========================================\n","# PASTE YOUR FILENAMES HERE\n","# ==========================================\n","\n","# A. Most Bluesy Blues (The \"Perfect\" Example)\n","play_specific_song(\"blues.Whiskey_Blues___B_B__King_Style_Blues_For_Escape___1_Hour_Deep_Soul.106.wav\")\n","\n","# B. Least Bluesy Blues (The \"Outlier\")\n","play_specific_song(\"blues.Alabama_Shakes___Always_Alright__Live_on_SNL_.007.wav\")\n","\n","# C. Most Bluesy Non-Blues (The \"Impostor\")\n","play_specific_song(\"not_blues.The_Notorious_B_I_G____Sky_s_The_Limit__Official_Music_Video___4K_.001.wav\")\n","\n","# D. Least Bluesy Non-Blues (The \"Obvious\" Non-Blues)\n","play_specific_song(\"not_blues.Rick_Ross___Hold_Me_Back__Explicit_.001.wav\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320,"output_embedded_package_id":"1CmKF5QrKYRSCTjGM7UUrxhI2OCBpBjK5"},"id":"yPzeOidPAT1d","executionInfo":{"status":"ok","timestamp":1765483667884,"user_tz":360,"elapsed":1311,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"765da8ce-a6aa-4208-8cdf-7ddd39d729dc"},"id":"yPzeOidPAT1d","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","\n","# 1. UPDATE THE PATH TO MATCH YOUR SCREENSHOT\n","# Changed \"final_solution\" to \"final_project\"\n","NOTEBOOKS_DIR = \"/content/drive/MyDrive/cs441/final_project\"\n","NOTEBOOK_NAME = \"CS441_Final.ipynb\"\n","\n","# 2. MOUNT DRIVE\n","if not os.path.exists(\"/content/drive\"):\n","    drive.mount(\"/content/drive/\")\n","elif len(os.listdir(\"/content/drive\")) == 0:\n","    drive.mount(\"/content/drive/\")\n","else:\n","    print(\"‚úÖ Drive is already mounted.\")\n","\n","# 3. VERIFY & CONVERT\n","NOTEBOOK_PATH = f\"{NOTEBOOKS_DIR}/{NOTEBOOK_NAME}\"\n","\n","if not os.path.exists(NOTEBOOK_PATH):\n","    print(f\"‚ùå ERROR: File STILL not found at: {NOTEBOOK_PATH}\")\n","    print(\"Double check that 'CS441_Final.ipynb' is definitely in the 'final_project' folder.\")\n","else:\n","    print(f\"üìÑ Found notebook: {NOTEBOOK_PATH}\")\n","    print(\"‚è≥ Installing PDF tools...\")\n","\n","    # Install dependencies quietly\n","    !apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic -qq > /dev/null\n","\n","    print(\"üîÑ Converting to PDF...\")\n","    !jupyter nbconvert \"$NOTEBOOK_PATH\" --to pdf\n","\n","    # Check result\n","    NOTEBOOK_PDF = NOTEBOOK_PATH.rsplit('.', 1)[0] + '.pdf'\n","    if os.path.exists(NOTEBOOK_PDF):\n","        print(f\"\\nüéâ PDF CREATED: {NOTEBOOK_PDF}\")\n","    else:\n","        print(\"\\n‚ùå PDF creation failed. Check logs.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnai5xulLkfk","executionInfo":{"status":"ok","timestamp":1765487385499,"user_tz":360,"elapsed":10,"user":{"displayName":"Cooper Sweet","userId":"00367006907407676389"}},"outputId":"047b1755-03bd-4164-e1de-677de711f097"},"id":"xnai5xulLkfk","execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Drive is already mounted.\n","‚ùå ERROR: File STILL not found at: /content/drive/MyDrive/cs441/final_project/CS441_Final.ipynb\n","Double check that 'CS441_Final.ipynb' is definitely in the 'final_project' folder.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HfasbypsLtxk"},"id":"HfasbypsLtxk","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"","name":""},"language_info":{"name":""},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}